# Role
你是一位精通 Python (BeautifulSoup4) 和 **技术 SEO (Technical SEO)** 的资深架构师。

# Objective
编写一个企业级的 `build.py` 自动化维护脚本。
**核心原则**：
1.  **布局同步 (Layout Sync)**：以 `index.html` 为单一数据源，全自动将首页的 Header 和 Footer 同步到所有子页面。
2.  **不动侧边栏 (Sidebar Safety)**：严格保留 `<aside>` 内原有的人工高颜值销售组件设计，**严禁修改或覆盖**。
3.  **SEO 增强 (Global SEO)**：针对 **“全球中文市场”** 进行配置，实现 Clean URL、Hreflang 定位、双重索引保险和结构化数据注入。

# Core Workflow (核心工作流)

### Phase 1: 链接治理标准 (Link Governance Standards)
定义一个全局的链接清洗逻辑，应用于脚本处理的所有 HTML 区域（包括同步过来的 Header/Footer）：
1.  **Clean URL (去后缀)**：全站所有内部链接 (`href`) 必须移除 `.html` 后缀（例如 `about.html` -> `/about`）。
2.  **根路径强制**：所有链接必须以 `/` 开头（锚点链接除外），防止在子目录 (`/blog/`) 中链接失效。
3.  **Canonical (唯一规范链接)**：为每个页面生成 `<link rel="canonical">`，指向其 Clean URL 版本。

### Phase 2: SEO 注入引擎 (The SEO Engine)
遍历 `blog/` 下的所有文章，对 `<head>` 区域执行重建：

1.  **全球中文定位**：
    * 注入 `<meta http-equiv="content-language" content="zh-CN" />`。
    * 注入 **Hreflang 矩阵** (`x-default`, `zh`, `zh-CN`)，指向当前页面的 Clean URL。
2.  **索引双重保险**：
    * 注入 `<meta name="robots" content="index, follow, max-image-preview:large" />`。
    * 注入 `<meta name="distribution" content="global" />`。
3.  **结构化数据 (Rich Schema)**：
    * 生成 `BlogPosting` JSON-LD。
    * **关键字段**：`headline`, `description`, `datePublished`, `author`, `mainEntityOfPage` (Clean URL)。
    * **Schema 面包屑**：生成 `BreadcrumbList` Schema，确保与视觉面包屑层级一致。

### Phase 3: 内容聚合与同步 (Aggregation & Sync)
1.  **布局同步 (Layout Sync - 关键)**:
    * **提取**: 读取 `index.html` 的 `<nav>` (Header) 和 `<footer>`。
    * **清洗**: 对提取出的 HTML 执行 **Clean URL** 处理（确保链接为 `/` 开头且无后缀）。
    * **注入**: 覆盖注入到 `blog/` 下所有文章页，替换原有的导航和页脚。
2.  **视觉面包屑 (Visual Breadcrumbs)**:
    * **动作**: 在 `<main>` 容器顶部自动生成并注入面包屑导航 HTML。
    * **结构**: `首页 > 博客 > [当前文章标题]` (链接需为 Clean URL)。
3.  **智能推荐 (Smart Interlinking)**:
    * 建立全站文章索引。基于关键词匹配度，在 `<article>` 底部注入“推荐阅读”模块。
4.  **全局更新**:
    * **首页**: 提取最新文章更新首页“最新资讯”。
    * **列表页**: 重构 `/blog/index.html`，生成列表及 `CollectionPage` Schema。

# Technical Constraints (技术铁律)
1.  **严禁触碰侧边栏**: 脚本在处理 Body 内容时，必须跳过 `<aside>` 标签，保留其原始代码。
2.  **Meta 清洗**: 在注入新 SEO 标签前，先移除旧的重复标签。
3.  **鲁棒性**: 遇到缺少 Meta 信息的文章，使用文件修改时间兜底。

请提供完整的 `build.py` 代码。